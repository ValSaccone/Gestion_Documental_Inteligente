{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:41.048527Z",
     "start_time": "2025-12-02T00:23:31.254208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ],
   "id": "467f86b48f27fbf5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:44.926793Z",
     "start_time": "2025-12-02T00:23:44.895551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocesar_imagen(ruta_origen, ruta_destino, size=(1280, 1280)):\n",
    "    \"\"\"\n",
    "    Lee una imagen, aplica preprocesamiento y la guarda en ruta_destino.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(ruta_origen, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(f\"‚ö† Error al leer {ruta_origen}\")\n",
    "        return False\n",
    "\n",
    "    # 1. Aumentar contraste\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    contrastada = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # 2. Reducci√≥n de ruido\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(contrastada, None, 10, 10, 7, 21)\n",
    "\n",
    "    # 3. Resize\n",
    "    resized = cv2.resize(denoised, size)\n",
    "\n",
    "    # 4. Guardar\n",
    "    cv2.imwrite(ruta_destino, resized)\n",
    "    return True\n"
   ],
   "id": "9757fcf285fb797d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:47.144476Z",
     "start_time": "2025-12-02T00:23:47.110498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dividir_dataset_con_anotaciones(dataset_original, dataset_dividido,\n",
    "                                    train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Divide im√°genes + anotaciones .txt en train/val/test y preprocesa antes de moverlas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpetas\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(dataset_dividido, split, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dataset_dividido, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "    # Listar im√°genes originales\n",
    "    imagenes = [f for f in os.listdir(dataset_original)\n",
    "                if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    random.shuffle(imagenes)\n",
    "\n",
    "    n = len(imagenes)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_imgs = imagenes[:n_train]\n",
    "    val_imgs = imagenes[n_train:n_train + n_val]\n",
    "    test_imgs = imagenes[n_train + n_val:]\n",
    "\n",
    "    # Helper interno\n",
    "    def mover_con_label(lista_imgs, split_name):\n",
    "        folder_img = os.path.join(dataset_dividido, split_name, \"images\")\n",
    "        folder_lbl = os.path.join(dataset_dividido, split_name, \"labels\")\n",
    "\n",
    "        for img in lista_imgs:\n",
    "            ruta_img = os.path.join(dataset_original, img)\n",
    "            ruta_lbl = os.path.splitext(ruta_img)[0] + \".txt\"\n",
    "\n",
    "            # Validar que haya anotaci√≥n\n",
    "            if not os.path.exists(ruta_lbl):\n",
    "                print(f\"‚ö† La imagen {img} NO tiene anotaci√≥n TXT. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Preprocesar ANTES de mover\n",
    "            destino_img = os.path.join(folder_img, img)\n",
    "            preprocesar_imagen(ruta_img, destino_img)\n",
    "\n",
    "            # Copiar anotaci√≥n\n",
    "            destino_lbl = os.path.join(folder_lbl, os.path.splitext(img)[0] + \".txt\")\n",
    "            shutil.copy(ruta_lbl, destino_lbl)\n",
    "\n",
    "    mover_con_label(train_imgs, \"train\")\n",
    "    mover_con_label(val_imgs, \"val\")\n",
    "    mover_con_label(test_imgs, \"test\")\n",
    "\n",
    "    print(\"‚úÖ Divisi√≥n de dataset completada (con anotaciones).\")\n"
   ],
   "id": "d66c68995b2642a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:47.736340Z",
     "start_time": "2025-12-02T00:23:47.705254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def entrenar_yolo(config_yaml, epochs=30, imgsz=1280):\n",
    "    \"\"\"\n",
    "    Entrena YOLOv8n utilizando la configuraci√≥n YAML del dataset.\n",
    "    \"\"\"\n",
    "    print(\"Cargando modelo YOLOv8n...\")\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    print(model)\n",
    "\n",
    "    print(\"Iniciando entrenamiento...\")\n",
    "    results = model.train(\n",
    "        data=config_yaml,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=4,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        patience=4\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Entrenamiento finalizado.\")\n",
    "    return model, results\n"
   ],
   "id": "a3204f34e5e5fc54",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:48.367972Z",
     "start_time": "2025-12-02T00:23:48.352345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validar_modelo(modelo, ruta_yaml):\n",
    "    \"\"\"\n",
    "    Ejecuta validaci√≥n sobre el dataset de validaci√≥n.\n",
    "    \"\"\"\n",
    "    print(\"üìä Ejecutando validaci√≥n...\")\n",
    "    metrics = modelo.val(data=ruta_yaml)\n",
    "    print(\"üìà M√©tricas:\", metrics)\n",
    "    return metrics\n"
   ],
   "id": "571dc940c1001f16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ejecucion de Pipline",
   "id": "673128912a3f46f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:23:52.984824Z",
     "start_time": "2025-12-02T00:23:52.969387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Configuracion de rutas\n",
    "\n",
    "dataset_original = \"../dataset/dataset_imagenes\"\n",
    "dataset_dividido = \"./dataset_dividido\"\n",
    "ruta_yaml = \"./etiquetas_yolo.yaml\"\n"
   ],
   "id": "58ea61deec041524",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:01:30.758056Z",
     "start_time": "2025-11-27T22:34:37.111200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividir Dataset\n",
    "dividir_dataset_con_anotaciones(dataset_original, dataset_dividido)"
   ],
   "id": "aa4c9d260fb640dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Divisi√≥n de dataset completada (con anotaciones).\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T00:39:03.601918Z",
     "start_time": "2025-12-02T00:34:40.825604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entrenar modelo\n",
    "modelo, resultados = entrenar_yolo(ruta_yaml, epochs=50)"
   ],
   "id": "f518e46d4b009ad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Cargando modelo YOLOv8n...\n",
      "üü¢ Iniciando entrenamiento...\n",
      "New https://pypi.org/project/ultralytics/8.3.234 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.232  Python-3.10.19 torch-2.7.1+cu118 CPU (Intel Core i5-6200U 2.30GHz)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./etiquetas_yolo.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Universidad\\PS\\CdigoPS\\Gestion_Documental_Inteligente\\runs\\detect\\train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001B[KDownloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\vales\\AppData\\Roaming\\Ultralytics\\Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 3.0MB/s 0.2s 0.2s<0.0s\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752872  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,408 parameters, 3,012,392 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access  (ping: 0.40.2 ms, read: 6.42.3 MB/s, size: 137.8 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Universidad\\PS\\C√≥digoPS\\Gestion_Documental_Inteligente\\ML_module\\dataset_dividido\\train\\labels... 28 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 28/28 68.8it/s 0.4s0.1s\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Universidad\\PS\\CdigoPS\\Gestion_Documental_Inteligente\\ML_module\\dataset_dividido\\train\\labels.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access  (ping: 0.70.2 ms, read: 5.22.4 MB/s, size: 94.2 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Universidad\\PS\\C√≥digoPS\\Gestion_Documental_Inteligente\\ML_module\\dataset_dividido\\val\\labels... 8 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 256.0it/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Universidad\\PS\\CdigoPS\\Gestion_Documental_Inteligente\\ML_module\\dataset_dividido\\val\\labels.cache\n",
      "Plotting labels to C:\\Universidad\\PS\\CdigoPS\\Gestion_Documental_Inteligente\\runs\\detect\\train4\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Universidad\\PS\\CdigoPS\\Gestion_Documental_Inteligente\\runs\\detect\\train4\u001B[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001B[K       1/50         0G      2.821      5.099      2.305         87       1280: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 23.6s/it 2:45.2ss\n",
      "WARNING NMS time limit 2.400s exceeded\n",
      "\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 13.3s/it 13.3s\n",
      "                   all          8         60    0.00917      0.109     0.0124    0.00442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001B[K       2/50         0G      2.678      4.526      2.196         77       1280: 29% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2/7 36.8s/it 1:02<3:040\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Entrenar modelo\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m modelo, resultados \u001B[38;5;241m=\u001B[39m \u001B[43mentrenar_yolo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mruta_yaml\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[4], line 9\u001B[0m, in \u001B[0;36mentrenar_yolo\u001B[1;34m(config_yaml, epochs, imgsz)\u001B[0m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolov8n.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müü¢ Iniciando entrenamiento...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_yaml\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimgsz\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_available\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m     15\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124müèÅ Entrenamiento finalizado.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model, results\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\ultralytics\\engine\\model.py:773\u001B[0m, in \u001B[0;36mModel.train\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    770\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mget_model(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39myaml)\n\u001B[0;32m    771\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m--> 773\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    774\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\ultralytics\\engine\\trainer.py:243\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    240\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 243\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\ultralytics\\engine\\trainer.py:434\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    431\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m*\u001B[39m i \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items) \u001B[38;5;241m/\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    433\u001B[0m \u001B[38;5;66;03m# Backward\u001B[39;00m\n\u001B[1;32m--> 434\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ni \u001B[38;5;241m-\u001B[39m last_opt_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccumulate:\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_step()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\torch\\_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    647\u001B[0m     )\n\u001B[1;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env_gestion_documental\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    825\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    826\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validar modelo\n",
    "validar_modelo(modelo, ruta_yaml)"
   ],
   "id": "6c13a60a8e949af0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO # Importar para verificar el guardado\n",
    "\n",
    "# --- 1. CONFIGURACI√ìN DE RUTAS ---\n",
    "NOMBRE_RUN = 'train'\n",
    "\n",
    "# Ruta de origen\n",
    "RUTA_ORIGEN = os.path.join('runs', 'detect', NOMBRE_RUN, 'weights', 'best.pt')\n",
    "\n",
    "# Carpeta de destino final\n",
    "CARPETA_FINAL = 'models'\n",
    "\n",
    "# Nombre final que tendr√° el modelo\n",
    "NOMBRE_MODELO_FINAL = 'model_yolo8n_v1_best.pt'\n",
    "RUTA_FINAL = os.path.join(CARPETA_FINAL, NOMBRE_MODELO_FINAL)\n",
    "\n",
    "# --- 2. PROCESO DE COPIA ---\n",
    "\n",
    "print(f\"Buscando modelo en: {RUTA_ORIGEN}\")\n",
    "\n",
    "# Crear la carpeta de destino si no existe\n",
    "os.makedirs(CARPETA_FINAL, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Copiar el archivo 'best.pt' al destino final con un nuevo nombre\n",
    "    shutil.copy(RUTA_ORIGEN, RUTA_FINAL)\n",
    "\n",
    "    print(f\"\\n‚úÖ Modelo copiado exitosamente a: {RUTA_FINAL}\")\n",
    "    print(f\"Ruta Absoluta: {os.path.abspath(RUTA_FINAL)}\")\n",
    "\n",
    "    # --- 3. VERIFICACI√ìN---\n",
    "    # Cargar el modelo guardado para asegurar que sea funcional\n",
    "    # modelo_final = YOLO(RUTA_FINAL)\n",
    "    # print(\"\\nModelo cargado y verificado: ¬°listo para usarse!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n‚ùå ERROR: No se encontr√≥ el modelo en la ruta de origen: {RUTA_ORIGEN}\")\n",
    "    print(\"Verifica que la carpeta 'runs/detect/' exista y que el NOMBRE_RUN ('train') sea correcto.\")"
   ],
   "id": "a8ca3e7d82768d82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
