{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:43:23.019643Z",
     "start_time": "2025-11-25T01:42:07.718562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from ultralytics import YOLO"
   ],
   "id": "3f23e4aafe3dcc78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\vales\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocesar_imagen(ruta_origen, ruta_destino, size=(1280, 1280)):\n",
    "    \"\"\"\n",
    "    Lee una imagen, aplica preprocesamiento y la guarda en ruta_destino.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(ruta_origen, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(f\"‚ö† Error al leer {ruta_origen}\")\n",
    "        return False\n",
    "\n",
    "    # 1. Aumentar contraste\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    lab = cv2.merge((cl, a, b))\n",
    "    contrastada = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # 2. Reducci√≥n de ruido\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(contrastada, None, 10, 10, 7, 21)\n",
    "\n",
    "    # 3. Resize\n",
    "    resized = cv2.resize(denoised, size)\n",
    "\n",
    "    # 4. Guardar\n",
    "    cv2.imwrite(ruta_destino, resized)\n",
    "    return True\n"
   ],
   "id": "f80a0cee9966cb1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def dividir_dataset_con_anotaciones(dataset_original, dataset_dividido,\n",
    "                                    train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Divide im√°genes + anotaciones .txt en train/val/test y preprocesa antes de moverlas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpetas\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(dataset_dividido, split, \"images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dataset_dividido, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "    # Listar im√°genes originales\n",
    "    imagenes = [f for f in os.listdir(dataset_original)\n",
    "                if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    random.shuffle(imagenes)\n",
    "\n",
    "    n = len(imagenes)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_imgs = imagenes[:n_train]\n",
    "    val_imgs = imagenes[n_train:n_train + n_val]\n",
    "    test_imgs = imagenes[n_train + n_val:]\n",
    "\n",
    "    # Helper interno\n",
    "    def mover_con_label(lista_imgs, split_name):\n",
    "        folder_img = os.path.join(dataset_dividido, split_name, \"images\")\n",
    "        folder_lbl = os.path.join(dataset_dividido, split_name, \"labels\")\n",
    "\n",
    "        for img in lista_imgs:\n",
    "            ruta_img = os.path.join(dataset_original, img)\n",
    "            ruta_lbl = os.path.splitext(ruta_img)[0] + \".txt\"\n",
    "\n",
    "            # Validar que haya anotaci√≥n\n",
    "            if not os.path.exists(ruta_lbl):\n",
    "                print(f\"‚ö† La imagen {img} NO tiene anotaci√≥n TXT. Saltando.\")\n",
    "                continue\n",
    "\n",
    "            # Preprocesar ANTES de mover\n",
    "            destino_img = os.path.join(folder_img, img)\n",
    "            preprocesar_imagen(ruta_img, destino_img)\n",
    "\n",
    "            # Copiar anotaci√≥n\n",
    "            destino_lbl = os.path.join(folder_lbl, os.path.splitext(img)[0] + \".txt\")\n",
    "            shutil.copy(ruta_lbl, destino_lbl)\n",
    "\n",
    "    mover_con_label(train_imgs, \"train\")\n",
    "    mover_con_label(val_imgs, \"val\")\n",
    "    mover_con_label(test_imgs, \"test\")\n",
    "\n",
    "    print(\"‚úÖ Divisi√≥n de dataset completada (con anotaciones).\")\n"
   ],
   "id": "d66c68995b2642a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def entrenar_yolo(config_yaml, epochs=50, imgsz=1280):\n",
    "    \"\"\"\n",
    "    Entrena YOLOv8n utilizando la configuraci√≥n YAML del dataset.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Cargando modelo YOLOv8n...\")\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    print(\"üü¢ Iniciando entrenamiento...\")\n",
    "    results = model.train(\n",
    "        data=config_yaml,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=4,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Entrenamiento finalizado.\")\n",
    "    return model, results\n"
   ],
   "id": "a3204f34e5e5fc54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validar_modelo(modelo, ruta_yaml):\n",
    "    \"\"\"\n",
    "    Ejecuta validaci√≥n sobre el dataset de validaci√≥n.\n",
    "    \"\"\"\n",
    "    print(\"üìä Ejecutando validaci√≥n...\")\n",
    "    metrics = modelo.val(data=ruta_yaml)\n",
    "    print(\"üìà M√©tricas:\", metrics)\n",
    "    return metrics\n"
   ],
   "id": "571dc940c1001f16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ejecucion de Pipline",
   "id": "673128912a3f46f9"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Configuracion de rutas\n",
    "\n",
    "dataset_original = \"../dataset_imagenes\"\n",
    "dataset_dividido = \"./dataset_dividido\"\n",
    "ruta_yaml = \"./etiquetas_yolo.yaml\"\n"
   ],
   "id": "58ea61deec041524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dividir Dataset\n",
    "dividir_dataset_con_anotaciones(dataset_original, dataset_dividido)"
   ],
   "id": "aa4c9d260fb640dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Entrenar modelo\n",
    "modelo, resultados = entrenar_yolo(ruta_yaml, epochs=50)"
   ],
   "id": "f518e46d4b009ad5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validar modelo\n",
    "validar_modelo(modelo, ruta_yaml)"
   ],
   "id": "6c13a60a8e949af0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
